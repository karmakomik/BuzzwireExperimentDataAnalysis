{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_rows', None)\n",
    "#os.getcwd()\n",
    "#print(open(\"Data/Level_1_Trial_1/resp_1000_Events_000.txt\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create empty dataframe with desired structure\n",
    "processedDF = pd.DataFrame(columns=['Participant_ID','Level_No','Trial_No', 'Task_Duration', 'Mistake_Count', 'Baseline_HR', 'Baseline_GSR', 'Task_Avg_HR_Raw','Task_Avg_GSR_Raw', 'Task_Avg_RR_Raw'])\n",
    "\n",
    "#iterate through participants, levels and trials\n",
    "for i in range(1000,1006): #Participant number   \n",
    "    \n",
    "    #print('\\nData for participant',i,'\\n-----------------------------')      \n",
    "    #Calculate baseline for 1000 participant\n",
    "    baseline_hr_df = pd.read_csv('Data/Baseline/resp_' + str(i) + '_Events_001.txt',  sep='\\t', lineterminator='\\n')\n",
    "    baseline_hr =  baseline_hr_df['Heart rate'].mean()\n",
    "    #print('Baseline HR -', baseline_hr_df['Heart rate'].mean())\n",
    "    baseline_gsr_df = pd.read_csv('Data/Baseline/resp_' + str(i) + '_Events_003.txt',  sep='\\t', lineterminator='\\n')\n",
    "    baseline_gsr = baseline_gsr_df['GSR Conductance CAL'].mean()\n",
    "    #print('Baseline GSR -', baseline_gsr_df['GSR Conductance CAL'].mean())\n",
    "      \n",
    "    for j in range(1, 7): #Level number\n",
    "        for k in range(1, 4): #Trial number\n",
    "            loc_str = 'Data/Level_' + str(j) + '_Trial_' + str(k)\n",
    "            eventMarkerdf = pd.read_csv((loc_str + '/resp_' + str(i) + '_Events_004.txt'),  sep='\\t', lineterminator='\\n')\n",
    "            hr_df = pd.read_csv((loc_str + '/resp_' + str(i) + '_Events_001.txt'),  sep='\\t', lineterminator='\\n')\n",
    "            gsr_df = pd.read_csv((loc_str + '/resp_' + str(i) + '_Events_003.txt'),  sep='\\t', lineterminator='\\n')\n",
    "            #print(eventMarkerdf)\n",
    "            #df.at[0,'Id:L;Name:StartTask;Key:A']\n",
    "            task_start_time = eventMarkerdf.loc[eventMarkerdf['Data'] == 'Id:L;Name:StartTask;Key:A']['TimeStamp'].values[0]\n",
    "            task_end_time = eventMarkerdf.loc[eventMarkerdf['Data'] == 'Id:L;Name:EndTask;Key:D']['TimeStamp'].values[0]\n",
    "            \n",
    "            mistakeAlldf = pd.read_csv((loc_str + '/resp_' + str(i) + '_Events_002.txt'),  sep='\\t', lineterminator='\\n')\n",
    "            #print(mistakeAlldf.shape)\n",
    "            mistakeTimeStampsdf = mistakeAlldf[mistakeAlldf['TimeStamp'].between(task_start_time, task_end_time)]['TimeStamp']\n",
    "            mistakeCount = 0\n",
    "            #print(mistakeTimeStampsdf.shape)   \n",
    "            for m in range(1,len(mistakeTimeStampsdf)): \n",
    "                #print('Currently processing ', mistakeTimeStampsdf.iloc[i])\n",
    "                timeDiff = mistakeTimeStampsdf.iloc[m] - mistakeTimeStampsdf.iloc[m-1]\n",
    "                #print('Difference with last time stamp- ', timeDiff)\n",
    "                if(timeDiff > 40): #mistake detected if within the timeDiff threshold\n",
    "                    mistakeCount+=1\n",
    "        \n",
    "            mistakeCount += 1 #For counting the last mistake which is ignored by the above logic   \n",
    "            \n",
    "            task_time_secs = (task_end_time - task_start_time) / 1000 \n",
    "            \n",
    "            avg_raw_hr = hr_df[hr_df['TimeStamp'].between(task_start_time, task_end_time)]['Heart rate'].mean()\n",
    "            avg_raw_rr_interval = hr_df[hr_df['TimeStamp'].between(task_start_time, task_end_time)]['R-R interval'].mean()\n",
    "            avg_raw_gsr = gsr_df[gsr_df['TimeStamp'].between(task_start_time, task_end_time)]['GSR Conductance CAL'].mean() \n",
    "            #print('Data for Level',j,', Trial',k)\n",
    "            #print('Time taken for trial - ', task_time_secs)\n",
    "            #print('Average HR (Raw) - ', avg_raw_hr)\n",
    "            #print('Average GSR (Raw) - ', avg_raw_gsr)\n",
    "            processedDF = processedDF.append({'Participant_ID': i, 'Level_No': j, 'Trial_No': k, 'Task_Duration': task_time_secs, 'Mistake_Count': mistakeCount, 'Baseline_HR': baseline_hr, 'Baseline_GSR': baseline_gsr, 'Task_Avg_HR_Raw': avg_raw_hr, 'Task_Avg_GSR_Raw': avg_raw_gsr, 'Task_Avg_RR_Raw' : avg_raw_rr_interval}, ignore_index=True)\n",
    "            #df.iloc[0]['Id:L;Name:StartTask;Key:A']\n",
    "            \n",
    "#print(processedDF)\n",
    "processedDF.to_csv('processedDF.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
